{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 524 entries, 310 to 102\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   filename  524 non-null    object \n",
      " 1   label     524 non-null    object \n",
      " 2   offset    524 non-null    float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 16.4+ KB\n",
      "Train: 419\n",
      "Test: 105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 419/419 [00:10<00:00, 40.50it/s]\n",
      "100%|██████████| 105/105 [00:02<00:00, 41.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train: (419, 40, 130)\n",
      "X test: (105, 40, 130)\n",
      "X train: (419, 40, 130, 1)\n",
      "Y train: (419, 2)\n",
      "X test: (105, 40, 130, 1)\n",
      "Y test: (105, 2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Audio\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# Scikit learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Keras\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "dataset = []\n",
    "\n",
    "label_replacements = {\n",
    "    \"20240505\": \"abnormal\",\n",
    "    \"20240417\": \"normal\"\n",
    "}\n",
    "for folder in [r\"\\Users\\User\\heartbeat\\heartBeat-project\\input\\set_c\\**\",r\"\\Users\\User\\heartbeat\\heartBeat-project\\input\\set_d\\**\"]:\n",
    "    for filename in glob.iglob(folder):\n",
    "        if os.path.exists(filename):\n",
    "            label = os.path.basename(filename).split(\"_\")[0]\n",
    "            label = label_replacements.get(label, label)\n",
    "            duration = librosa.get_duration(filename=filename)\n",
    "            # skip audio smaller than 3 secs\n",
    "            if duration>=3:\n",
    "                slice_size = 3\n",
    "                iterations = int((duration-slice_size)/(slice_size-1))\n",
    "                iterations += 1\n",
    "#                 initial_offset = (duration % slice_size)/2\n",
    "                initial_offset = (duration - ((iterations*(slice_size-1))+1))/2\n",
    "                # if label not in [\"Aunlabelledtest\", \"Bunlabelledtest\", \"artifact\"]:\n",
    "                for i in range(iterations):\n",
    "                    offset = initial_offset + i*(slice_size-1)\n",
    "                    if (label == \"normal\"):\n",
    "                        dataset.append({\n",
    "                                \"filename\": filename,\n",
    "                                \"label\": \"normal\",\n",
    "                                \"offset\": offset\n",
    "                            })\n",
    "                    else:\n",
    "                        dataset.append({\n",
    "                                \"filename\": filename,\n",
    "                                \"label\": \"abnormal\",\n",
    "                                \"offset\": offset\n",
    "                            })\n",
    "                        \n",
    "dataset = pd.DataFrame(dataset)\n",
    "dataset = shuffle(dataset, random_state=42)\n",
    "dataset.info()\n",
    "\n",
    "train, test = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Train: %i\" % len(train))\n",
    "print(\"Test: %i\" % len(test))\n",
    "\n",
    "def extract_features(audio_path,offset):\n",
    "#     y, sr = librosa.load(audio_path, duration=3)\n",
    "    y, sr = librosa.load(audio_path, offset=offset, duration=3)\n",
    "#     y = librosa.util.normalize(y)\n",
    "    \n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, \n",
    "                                   hop_length=512, \n",
    "                                   n_mels=128)\n",
    "    mfccs = librosa.feature.mfcc(S=librosa.power_to_db(S), n_mfcc=40)\n",
    "\n",
    "#     mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "    return mfccs\n",
    "\n",
    "x_train = []\n",
    "x_test = []\n",
    "\n",
    "for idx in tqdm(range(len(train))):\n",
    "    x_train.append(extract_features(train.filename.iloc[idx],train.offset.iloc[idx]))\n",
    "\n",
    "for idx in tqdm(range(len(test))):\n",
    "    x_test.append(extract_features(test.filename.iloc[idx],test.offset.iloc[idx]))\n",
    "    \n",
    "x_test = np.asarray(x_test)\n",
    "x_train = np.asarray(x_train)\n",
    "\n",
    "print(\"X train:\", x_train.shape)\n",
    "print(\"X test:\", x_test.shape)\n",
    "\n",
    "# Encode Labels\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train.label)\n",
    "\n",
    "y_train = encoder.transform(train.label)\n",
    "y_test = encoder.transform(test.label)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "\n",
    "# Convert the result to a dictionary\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(\"X train:\", x_train.shape)\n",
    "print(\"Y train:\", y_train.shape)\n",
    "print(\"X test:\", x_test.shape)\n",
    "print(\"Y test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\\abnormal-test\\20240505_180655.m4a\n",
      "MoviePy - Writing audio in input/heartbeat_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Conversion complete!\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "[[9.9992716e-01 7.2869763e-05]]\n",
      "Abnormal heartbeat\n",
      "Confidence: 0.99992716\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import AudioFileClip\n",
    "import os\n",
    "\n",
    "def convert_mp4_audio_to_wav(input_file, output_file):\n",
    "    # Load the audio clip\n",
    "    audio_clip = AudioFileClip(input_file)\n",
    "    \n",
    "    # Write the audio clip to a WAV file\n",
    "    audio_clip.write_audiofile(output_file)\n",
    "    \n",
    "    # Close the audio clip\n",
    "    audio_clip.close()\n",
    "\n",
    "# File paths\n",
    "input_file = input(\"input the address of an audio file .. i.e. input/WhatsApp Audio 2024-05-20 at 9.37.19 PM.mpeg: \")\n",
    "print(input_file)\n",
    "output_file = \"input/heartbeat_audio.wav\"\n",
    "\n",
    "# Convert .mp4 to .wav\n",
    "convert_mp4_audio_to_wav(input_file, output_file)\n",
    "\n",
    "print(\"Conversion complete!\")\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "# load model\n",
    "model = load_model(\"heartbeat_classifier (normalised).h5\")\n",
    "\n",
    "# File to be classified\n",
    "# classify_file = \"input/set_d/20240417_223344_005.wav\" #20240417 normal\n",
    "\n",
    "classify_file = \"input/heartbeat_audio.wav\"\n",
    "x_test = []\n",
    "x_test.append(extract_features(classify_file, 0.5))\n",
    "x_test = np.asarray(x_test)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
    "pred = model.predict(x_test,verbose=1)\n",
    "\n",
    "print(pred)\n",
    "\n",
    "# Get the class index with the highest probability\n",
    "pred_class_index = np.argmax(pred)\n",
    "\n",
    "# Map the class index to the actual class label using the encoder\n",
    "classes = encoder.classes_\n",
    "pred_class_label = classes[pred_class_index]\n",
    "\n",
    "# Print the predicted class and confidence\n",
    "if pred_class_label == \"normal\":\n",
    "    print(\"Normal heartbeat\")\n",
    "    print(\"Confidence:\", pred[0][pred_class_index])\n",
    "elif pred_class_label == \"abnormal\":\n",
    "    print(\"Abnormal heartbeat\")\n",
    "    print(\"Confidence:\", pred[0][pred_class_index])\n",
    "else:\n",
    "    print(\"no hearbeat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
